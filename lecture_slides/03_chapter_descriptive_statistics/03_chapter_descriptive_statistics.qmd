---
title: "<span style = 'font-size: 100%;'> MGMT 30500: Business Statistics </span>"
subtitle: "<span style = 'font-size: 150%;'> Basic Stat. & Prob. Rvw. (cont.) </span>"
author: "Professor<br>Davi Moreira<br>"
date: "2024-08-01"
date-format: "MMMM DD, YYYY"
format:
  revealjs: 
    transition: slide
    background-transition: fade
    width: 1600
    height: 900
    center: true
    slide-number: true
    incremental: true
    chalkboard: 
      buttons: false
    preview-links: auto
    #logo: images/quarto.png
    footer: "Business Statistics"
    theme: [simple,custom.scss]
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
  
---

## Overview

::: {.nonincremental}

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}

-   Descriptive Statistics
-   Measures of Central Location and Variability
-   Distribution Shape

    -   Skewness
    -   Symmetry

-   Relative Location and z-Scores

    -   Calculation and Interpretation
    -   Examples

-   Empirical Rule

    -   68-95-99.7 Rule
    -   Detecting Outliers

:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

- Five-Number Summaries and Boxplots

- Measures of Association Between Two Variables

    - Covariance
    - Correlation


:::
:::

:::


# Descriptive Statistics {background-color="#cfb991"}

# Measures of Central Location and Variability {background-color="#cfb991"}

## Central Location {.smaller}

| **Statistic** | **Definition** | **Formula** |
|---------------|----------------|-------------|
| **Mean**      | The average of all values of a variable | $\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}$ |
| **Mode**      | The most frequently occurring value | |
| **k<sup>th</sup> Percentile** | Roughly k% of the data is at or below this value | |
| **Quartile**  | The first, second, and third quartiles are 25<sup>th</sup>, 50<sup>th</sup>, and 75<sup>th</sup> percentiles | $Q1, Q2, Q3$ |
| **Median**    | The "middle" observation when the data are listed from smallest to largest | $Q2$ |
| **Maximum**   | The largest value | |
| **Minimum**   | The smallest value | |
| **Midrange**  | The middle of the maximum and minimum | $\frac{Max + Min}{2}$ |
| **Midhinge**  | The middle of the first and third quartiles | $\frac{Q3 + Q1}{2}$ |

## Variability (Sampling Variation)

- **Sample Variance**: "Average" squared deviation of observations from the mean of all observations ($n-1$ is called the **degrees of freedom, df**):
  
  $$
  S^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}
  $$

    - Why do we compute the sample variance using $n-1$ instead of $n$? 
    - To not underestimate the True Population Variance $\sigma^2$
    - What is an unbiased estimator? [Video](https://www.youtube.com/watch?v=xJlwSkyeP0k)
    - [Video](https://www.khanacademy.org/math/ap-statistics/summarizing-quantitative-data-ap/more-standard-deviation/v/review-and-intuition-why-we-divide-by-n-1-for-the-unbiased-sample-variance) and [Simulation](https://www.khanacademy.org/computer-programming/unbiased-variance-visualization/1167453164)

- **Sample Standard Deviation**:
  
  $$
  S = \sqrt{S^2}
  $$

- **Range** = Maximum – Minimum.

- **Interquartile Range (IQR)** = 3rd Quartile – 1st Quartile  
  (Range of the middle 50% of data.)

# Distribution Shape 

## Distribution Shape: Skewness 

- An important measure of the shape of a distribution is called [**skewness**](https://en.wikipedia.org/wiki/Skewness).

- The formula for the skewness of sample data is:

  $$
  \text{Skewness} = \frac{n}{(n - 1)(n - 2)} \sum \left(\frac{x_i - \bar{x}}{s}\right)^3
  $$

- Skewness can be easily computed using statistical software.

## Distribution Shape: Skewness

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}
```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/01_skewness.png") 
```

<br>

:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

<br>
<br>

- Symmetric (not skewed)

    - Skewness is zero.
    - Mean and median are equal.

:::
:::


## Distribution Shape: Skewness

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}
```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/02_skewness.png") 
```

<br>

:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

<br>
<br>

- Moderately Skewed Left

    - Skewness is negative.
    - Mean will usually be less than the median.

:::
:::

## Distribution Shape: Skewness

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}
```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/03_skewness.png") 
```

<br>

:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

<br>
<br>

- Moderately Skewed Right
    
    - Skewness is positive.
    - Mean will usually be more than the median.

:::
:::

## Distribution Shape: Skewness

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}
```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/04_skewness.png") 
```

<br>
:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}
<br>
<br>

-  Highly Skewed Right

    - Skewness is positive (often above 1.0).
    - Mean will usually be more than the median.

:::
:::

# Relative Location - z-Scores {background-color="#cfb991"}

## z-Scores 

- The [**z-score**](https://en.wikipedia.org/wiki/Standard_score) is often called the standardized value.

- It describes the relative location of a data value relative to the mean.

- It denotes the number of standard deviations a data value $x_i$ is from the mean.

  $$
  Z_i = \frac{x_i - \bar{x}}{s}
  $$

- `=STANDARDIZE(x, mean, standard deviation)`

## z-Scores 

- An observation’s z-score is a measure of the relative location of the observation in a data set. 
- A data value less than the sample mean will have a z-score less than zero.
- A data value greater than the sample mean will have a z-score greater than zero.
- A data value equal to the sample mean will have a z-score of zero.

## z-Scores 

<br>

**Example:** `class_size_data.xlsx`

$$
Z_i = \frac{x_i - \bar{x}}{s}
$$

| Number of students in class | Deviation about the Mean | Z score                       |
|-----------------------------|--------------------------|-------------------------------|
| 46                          | 2                        | $\frac{2}{8} = 0.25$        |
| 54                          | 10                       | $\frac{10}{8} = 1.25$       |
| 42                          | -2                       | $\frac{-2}{8} = -0.25$      |
| 46                          | 2                        | $\frac{2}{8} = 0.25$        |
| 32                          | -12                      | $\frac{-12}{8} = -1.5$      |

<br>

::: aside
**Note:** $\bar{x} = 44$ and $s = 8$ for the given data.
:::


# z-Scores - Example

<br>
<br>

```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/zscore_excel.png") 
```

<br>

<center>

- `=STANDARDIZE(x, mean, standard deviation)`

</center>


# Empirical Rule - 68-95-99.7 Rule {background-color="#cfb991"}

## Empirical Rule - 68-95-99.7 Rule

<br>

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}

```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/empirical_rule.png")
```


:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

- When the data are believed to approximate a bell-shaped (normal) distribution:

    - The empirical rule can be used to determine the percentage of data values that must be within a specified number of standard deviations of the mean.

:::
:::


## Empirical Rule - 68-95-99.7 Rule


<br>

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}

```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/empirical_rule.png")
```


:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

- For nearly normally distributed data,
    
    - about 68% falls within 1 SD of the mean,
    - about 95% falls within 2 SD of the mean,
    - about 99.7% falls within 3 SD of the mean.

- It is possible for observations to fall 4, 5, or more standard deviations away from the mean, but these occurrences are very rare if the data are nearly normal.

:::
:::



## Empirical Rule - 68-95-99.7 Rule - Example

<br>

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}

```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/empirical_rule.png")
```


:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

- SAT scores are distributed nearly normally with mean 1500 and standard deviation 300.

    - ~68% of students score between 1200 and 1800 on the SAT.
    - ~95% of students score between 900 and 2100 on the SAT.
    - ~$99.7% of students score between 600 and 2400 on the SAT.

:::
:::

# Detecting Outliers {background-color="#cfb991"}

## Detecting Outliers

- An outlier is an unusually small or unusually large value in a data set.
- A data value with a z-score less than −3 or greater than +3 might be considered an outlier.
- It might be:

    - an incorrectly recorded data value
    - a data value that was incorrectly included in the data set
    - a correctly recorded unusual data value that belongs in the data set

## Detecting Outliers - Example

**Example:** `class_size_data.xlsx`

$$
Z_i = \frac{x_i - \bar{x}}{s}
$$

| Number of students in class | Deviation about the Mean | Z score                       |
|-----------------------------|--------------------------|-------------------------------|
| 46                          | 2                        | $\frac{2}{8} = 0.25$        |
| 54                          | 10                       | $\frac{10}{8} = 1.25$       |
| 42                          | -2                       | $\frac{-2}{8} = -0.25$      |
| 46                          | 2                        | $\frac{2}{8} = 0.25$        |
| 32                          | -12                      | $\frac{-12}{8} = -1.5$      |

- **Note:** $-1.5$ shows the fifth class size is farthest from the mean.
- No outliers are present as the z values are within the $\pm 3$ guideline.

# Five-Number Summaries and Boxplots {background-color="#cfb991"}

## Five-Number Summaries

<br>

- Smallest Value

- First Quartile (25th percentile)

- Median  (50th percentile)

- Third Quartile (75th percentile) 

- Largest Value

::: aside
::: fragment
**Note:**  $k-th$ percentile = `percentile.EXC(Data Array, k)`, where 0 ≤ k ≤ 1. 
:::
:::

## Five-Number Summaries - Example

**Example:** Monthly starting salary

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}


| Monthly Starting Salary ($) 
|-----------------------------| 
| 5,710                       |
| 5,755                       |
| 5,850                       |
| 5,880                       |
| 5,890                       |
| 5,920                       |
| 5,940                       |
| 5,950                       |
| 6,050                       |
| 6,130                       |
| 6,325                       |

<br>
:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}
<br>
<br>


- **Lowest Value** = 5,710
- **Third Quartile** = 6,025
- **Median** = 5,905
- **First Quartile** = 5,857.5
- **Largest Value** = 6,325


:::
:::


## Boxplot

<br>

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}

```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/boxplot_michelsonmorley.png")
```

::: {style="font-size: 70%;"}
<center>

[Michelson–Morley experiment - Wiki](https://en.wikipedia.org/wiki/Michelson%E2%80%93Morley_experiment#Michelson_experiment_(1881))

</center>
:::

:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

- A [**boxplot**](https://en.wikipedia.org/wiki/Box_plot) is a graphical summary of data that is based on a five-number summary.

- A key to the development of a boxplot is the computation of the median and the quartiles, $Q_1$ and $Q_3$.

- Boxplots provide another way to identify outliers.

:::
:::

## Boxplot

**Example:** `monthly_starting_salary.xlsx`

<br>

```{r  echo=FALSE, out.width = "70%",fig.align="center"}
knitr::include_graphics("figs/boxplot.png")
```

<br>

- A box is drawn with its ends located at the first and third quartiles.
- A vertical line is drawn in the box at the location of the median (second quartile).

<br>

## Boxplot

<br>

- Limits are located using the interquartile range (IQR).
- Data outside these limits are considered outliers.
- The locations of each outlier are shown with the symbol.
- The limits are not shown is a Boxplot.

## Boxplot

::: {style="font-size: 80%;"}
**Example:** `monthly_starting_salary.xlsx`
:::

<br>

```{r  echo=FALSE, out.width = "70%",fig.align="center"}
knitr::include_graphics("figs/boxplot.png")
```

<br>

::: {style="font-size: 80%;"}
- The lower limit is located 1.5(IQR) below $Q_1$.
  
    - Lower Limit: $Q_1 - 1.5(\text{IQR}) = 5,857.5 - 1.5(167.5) = 5,606.25$

- The upper limit is located 1.5(IQR) above $Q_3$.

    - Upper Limit: $Q_3 + 1.5(\text{IQR}) = 6,025 + 1.5(167.5) = 6,276.25$

- There is one outlier: 6,325.
:::

## Boxplot

<br>

<center>
**Distribution and Boxplot**
</center>

<br>

```{r  echo=FALSE, out.width = "70%",fig.align="center"}
knitr::include_graphics("figs/boxplot_distribution.png")
```

<br>

# Measures of Association Between Two Variables {background-color="#cfb991"}

## Covariance

<br>

```{r  echo=FALSE, out.width = "50%",fig.align="center"}
knitr::include_graphics("figs/scatter_plot.png")
```

<br>

- The covariance is a measure of the linear association between two variables.
- Positive values indicate a positive relationship.
- Negative values indicate a negative relationship.

<br>

<br>

## Covariance

<br>

- The covariance is computed as follows:

  **For population:**

  $$
  \sigma_{xy} = \frac{\sum (x_i - \mu_x)(y_i - \mu_y)}{N}
  $$

  **For samples:**

  $$
  s_{xy} = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{n - 1}
  $$

- **EXCEL for Sample covariance:** `=COVARIANCE.S(array1, array2)`


## Correlation Coefficient

<br>

```{r  echo=FALSE, out.width = "50%",fig.align="center"}
knitr::include_graphics("figs/xkcd.png")
```

<br>


- Correlation is a unit-free measure of linear association and not necessarily causation.

<br>

<br>

<br>

## Correlation Coefficient

<br>

```{r  echo=FALSE, out.width = "30%",fig.align="center"}
knitr::include_graphics("figs/spurious_correlations.png")
```

<center>
[Spurious Correlations!](https://www.tylervigen.com/spurious-correlations)
</center>

<br>

- Just because two variables are highly correlated, it does not mean that one variable is the cause of the other.

<br>
<br>
<br>

## Correlation Coefficient

- The correlation coefficient is computed as follows:

  **For population:**

  $$
  \rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y}
  $$

  **For samples:**

  $$
  r_{xy} = \frac{s_{xy}}{s_x s_y}
  $$

- **EXCEL:** `=correl(array1, array2)`


## Correlation Coefficient

<br>

- The coefficient can take on values between −1 and +1.
  
    - Values near −1 indicate a strong negative linear relationship.
    - Values near +1 indicate a strong positive linear relationship.
	  
- The closer the correlation is to zero, the weaker the relationship.

<br>

<center>

::: fragment
[Guess the correlation!](https://www.guessthecorrelation.com/)
:::

</center>

## Correlation Coefficient 

<br>

```{r  echo=FALSE, out.width = "40%",fig.align="center"}
knitr::include_graphics("figs/correlation_estimates.png")
```


**Rules of thumb:**

- \( 0.0 < |r| < 0.3 \) — *weak correlation*
- \( 0.3 < |r| < 0.7 \) — *moderate correlation*
- \( 0.7 < |r| < 1.0 \) — *strong correlation*

<br>

## Correlation Coefficient 

<br>

```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/correlation_linear.png")
```

<br>

::: {.nonincremental}

::: fragment
::: {style="font-size: 70%;"}
- The correlation reflects the strength and direction of a linear relationship (top row)
- The correlation does not reflect the slope of that relationship (middle)
- Nor many aspects of nonlinear relationships (bottom). 
- N.B.: the figure in the center has a slope of 0 but in that case the correlation coefficient is undefined because the variance of Y is zero.

<center>
[Wiki](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)
</center>

:::
:::
:::

<br>



## Covariance and Correlation Coefficient - Example

<br>

::: {style="font-size: 80%;"}
**Example:** `san_francisco_electronics_store.xlsx`
:::

<br>

::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}


| Week | Number of Commercials | Sales ($100s) |
|------|-----------------------|---------------|
| 1    | 2                     | 50            |
| 2    | 5                     | 57            |
| 3    | 1                     | 41            |
| 4    | 3                     | 54            |
| 5    | 4                     | 54            |
| 6    | 1                     | 38            |
| 7    | 5                     | 63            |
| 8    | 3                     | 48            |
| 9    | 4                     | 59            |
| 10   | 2                     | 46            |


:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

<br>

<br>

<br>

- The store’s manager wants to determine the relationship between the	number of weekend television commercials shown and the sales at the 	store during the following week. 

:::
:::


## Covariance and Correlation Coefficient - Example

<br>

::: {style="font-size: 80%;"}
**Example:** `san_francisco_electronics_store.xlsx`
:::

<br>


::: columns
::: {.column width="40%" style="text-align: center; justify-content: center; align-items: center;"}


|   $x_i$   |   $y_i$   |   $x_i - \bar{x}$   |   $y_i - \bar{y}$   |   $(x_i - \bar{x})(y_i - \bar{y})$   |
|:---------:|:---------:|:-------------------:|:-------------------:|:---------------------------:|
|     2     |     50    |         -1          |         -1          |                 1           |
|     5     |     57    |          2          |          6          |                 12          |
|     1     |     41    |         -2          |        -10          |                 20          |
|     3     |     54    |          0          |          3          |                 0           |
|     4     |     54    |          1          |          3          |                 3           |
|     1     |     38    |         -2          |        -13          |                 26          |
|     5     |     63    |          2          |         12          |                 24          |
|     3     |     48    |          0          |         -3          |                 0           |
|     4     |     59    |          1          |          8          |                 8           |
|     2     |     46    |         -1          |         -5          |                 5           |
| **Totals** |  **30**  |       **510**       |        **0**        |           **99**            |


:::

::: {.column width="60%" style="text-align: center; justify-content: center; align-items: center;"}

<br>

<br>

<br>

$$
s_{xy} = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{n - 1} = \frac{99}{10 - 1} = 11
$$


:::
:::



## Covariance and Correlation Coefficient - Example

<br>

::: {style="font-size: 80%;"}
**Example:** `san_francisco_electronics_store.xlsx`
:::

<br>

**Sample Covariance**

$$
s_{xy} = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{n - 1} = \frac{99}{10 - 1} = 11
$$

**Sample Correlation Coefficient**

$$
r_{xy} = \frac{s_{xy}}{s_x s_y} = \frac{11}{1.49 \times 7.93} = 0.93
$$


## Correlation Coefficient

<br>

$$
r_{xy} = \frac{s_{xy}}{s_x s_y} = \frac{1}{n-1} \sum \left(\frac{x_i - \bar{x}}{s_x}\right) \left(\frac{y_i - \bar{y}}{s_y}\right)
$$
<br>

- Correlation is a unit-free measure of linear relationship.
- Correlation is unchanged if one or both variables are linearly transformed.


# Using Excel to Compute Covariance and Correlation coefficient

## Using Excel to Compute Covariance and Correlation coefficient

Example: San Francisco Electronics Store

Excel Formula and Value Worksheets

```{r  echo=FALSE, out.width = "80%",fig.align="center"}
knitr::include_graphics("figs/covariance_excel.png")
```


# Summary  {background-color="#cfb991"}

## Summary

::: {.nonincremental}

Some key takeaways from this session:

-   **Descriptive Statistics**: help us to understand the data we have.

-   **Measures of Central Location and Variability**: Central location and variability metrics help us to summarize the data.

-   **Distribution Shape**: skewness can be used to understand the shape of a distribution.

-   **Relative Location and z-Scores**: z-scores to determine the relative position of data points within a distribution.

-   **Empirical Rule**: The 68-95-99.7 Rule for understanding data distribution in relation to the mean and standard deviation. Good for symetric distrubutions!

- **Covariance and Correlation**: to understand the relationship between two numerical variables.

:::

# Thank you! {background-color="#cfb991"}
